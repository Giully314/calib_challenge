{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import cv2 as cv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "class BGRtoRGB:\n",
    "    def __call__(self, frame):\n",
    "        return cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "class RGBtoBGR:\n",
    "    def __call__(self, frame):\n",
    "        return cv.cvtColor(frame, cv.COLOR_RGB2BGR)    \n",
    "\n",
    "class YUVtoBGR:    \n",
    "    def __call__(self, frame):\n",
    "        return cv.cvtColor(frame, cv.COLOR_YUV2BGR)    \n",
    "\n",
    "class ToOpenCV:\n",
    "    def __call__(self, frame):\n",
    "        return frame.permute(1, 2, 0).numpy()\n",
    "\n",
    "class Crop:\n",
    "    def __init__(self, y1, y2, x1, x2):\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return img[:, self.y1 : self.y2, self.x1 : self.x2]\n",
    "        \n",
    "\n",
    "def num_of_tensors_in_dir(dir: str) -> int:\n",
    "    return len([f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and \n",
    "                os.path.splitext(f)[1] == \".pt\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "videos = [0, 1, 3, 4]\n",
    "videos_parts = [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2], [0, 1, 2, 3, 4, 5]]\n",
    "videos_path = [os.path.join(str(video), str(part)) for video, parts in zip(videos, videos_parts) for part in parts]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "data_dir = \"src/data_aug3\"\n",
    "data = [os.path.join(data_dir, video) for video in videos_path]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "crop_args = [112, 232, 39, 349]\n",
    "crop = Crop(*crop_args)\n",
    "t = T.Compose([crop, ToOpenCV(), RGBtoBGR()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "video = data[0]\n",
    "for i in range(num_of_tensors_in_dir(video)):\n",
    "    frame = t(torch.load(os.path.join(video, str(i) + \".pt\")))\n",
    "    cv.imshow(\"output\", frame)\n",
    "    cv.waitKey(120)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}