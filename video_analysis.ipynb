{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "0.002 ** 2 "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4e-06"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_mse(gt, test):\n",
    "  test = np.nan_to_num(test)\n",
    "  return np.mean(np.nanmean((gt - test)**2, axis=0))\n",
    "\n",
    "def get_rmse(gt, test):\n",
    "  test = np.nan_to_num(test)\n",
    "  return np.sqrt(np.mean(np.nanmean((gt - test)**2, axis=0)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "videos_dir = \"src/videos/labeled\"\n",
    "angles = [os.path.join(videos_dir, str(i) + \".txt\") for i in range(5)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "zero_mses = []\n",
    "for i in range(0,5):\n",
    "  gt = np.loadtxt(angles[i]) \n",
    "  zero_mses.append(get_mse(gt, np.zeros_like(gt)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "m = np.mean(zero_mses)\n",
    "print(m)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0015175754160628898\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "0.00005 / m"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.03294729175945477"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "np.sqrt(0.00005)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.007071067811865475"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def crop_center(img,cropx,cropy):\n",
    "    y,x,c = img.shape\n",
    "    startx = x//2 - cropx//2\n",
    "    starty = y//2 - cropy//2    \n",
    "    return img[:, starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "def crop_opencv(img, x1, x2, y1, y2):\n",
    "    return img[y1 : y2, x1 : x2, :]\n",
    "\n",
    "def crop(img, x1, x2, y1, y2):\n",
    "    return img[:, y1 : y2, x1 : x2]\n",
    "\n",
    "def crop_height(img, y1, y2):\n",
    "    return img[y1:y2, :, :]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class Crop:\n",
    "    def __init__(self, x1, x2, y1, y2, opencv=True):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        self.opencv=opencv\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return crop_opencv(img, self.x1, self.x2, self.y1, self.y2) if self.opencv else crop(img, self.x1, self.x2, self.y1, self.y2)\n",
    "\n",
    "class BGRtoRGB:\n",
    "    def __call__(self, frame):\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "class RGBtoBGR:\n",
    "    def __call__(self, frame):\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)    \n",
    "\n",
    "class YUVtoBGR:    \n",
    "    def __call__(self, frame):\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_YUV2BGR)    \n",
    "\n",
    "class ToOpenCV:\n",
    "    def __call__(self, frame):\n",
    "        return frame.permute(1, 2, 0).numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class AnglesDataset(Dataset):\n",
    "    def __init__(self, filename, degrees=False):\n",
    "        self.degrees = degrees\n",
    "        pitch = []\n",
    "        yaw = []\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.split()      \n",
    "                if degrees:\n",
    "                    pitch.append(math.degrees(float(line[0])))\n",
    "                    yaw.append(math.degrees(float(line[1])))\n",
    "                else:\n",
    "                    pitch.append(float(line[0]))\n",
    "                    yaw.append(float(line[1]))\n",
    "                    \n",
    "        self.pitch = np.asarray(pitch)\n",
    "        self.yaw = np.asarray(yaw)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.pitch[idx], self.yaw[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pitch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def read_n_frames(video, n, transform=None):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    frames = []\n",
    "    if cap.isOpened():\n",
    "        for i in range(n):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if transform is not None:\n",
    "                frame = transform(frame)\n",
    "\n",
    "            frames.append(frame)\n",
    "        \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def read_frames(video, transform=None):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    frames = []\n",
    "    while cap.isOpened():      \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if transform is not None:\n",
    "            frame = transform(frame)\n",
    "\n",
    "        frames.append(frame)\n",
    "        \n",
    "    cap.release()\n",
    "    return frames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#rotate a column vector\n",
    "\n",
    "def get_rotation(angle, degree=True):\n",
    "    if degree:\n",
    "        angle = math.radians(angle)\n",
    "    matrix = np.array([[math.cos(angle), -math.sin(angle)],\n",
    "                      [math.sin(angle), math.cos(angle)]])\n",
    "    return matrix\n",
    "\n",
    "def get_inv_rotation(angle, degree=True):\n",
    "    matrix = get_rotation(angle, degree).T\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def rotate_v(v, angle, degree=True):\n",
    "    return get_rotation(angle, degree) @ v\n",
    "\n",
    "def inv_rotate_v(v, angle, degree=True):\n",
    "    return get_inv_rotation(angle, degree) @ v\n",
    "\n",
    "def draw_arrow(frame, v, pos, color=(255,255,255)):\n",
    "    v[1] *= -1\n",
    "    cv2.arrowedLine(frame, tuple(np.ceil(pos).astype(int)), tuple(np.ceil(pos + v).astype(int)), color, 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def show(img, t=None):\n",
    "    if t is not None:\n",
    "        img = t(img)\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "height = 874\n",
    "width = 1164\n",
    "\n",
    "h_div = 1\n",
    "w_div = 1\n",
    "\n",
    "n_height = int(height // h_div)\n",
    "n_width = int(width // w_div)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "n_width"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "video = \"4\"\n",
    "videos_dir = \"src/videos/labeled\"\n",
    "video_path = os.path.join(videos_dir, video + \".hevc\")\n",
    "angles_file = os.path.join(videos_dir, video + \".txt\")\n",
    "\n",
    "trf_resize = T.Resize((n_height, n_width))\n",
    "\n",
    "to_open_cv = T.Compose([ToOpenCV(), YUVtoBGR()])\n",
    "trf_crop = Crop(int(n_width * 0.2), int(n_width - n_width * 0.2), int(n_height *0.45), int(n_height - n_height * 0.2), False)\n",
    "transform = T.Compose([BGRtoRGB(), T.ToTensor(), trf_resize, trf_crop, ToOpenCV()])\n",
    "transform_nocrop = T.Compose([BGRtoRGB(), T.ToTensor(), trf_resize,ToOpenCV()])\n",
    "angles = np.loadtxt(angles_file)\n",
    "frames = read_frames(video_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# transform(frames[0]).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# transform(frames[0]).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# video = \"4\"\n",
    "# part = \"1\"\n",
    "# frames = torch.load(f\"src/data_prova/{video}/{part}.pt\")\n",
    "# angles = np.loadtxt(f\"src/data_prova/{video}/{part}.txt\", dtype=np.float64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# frames = read_frames(video_path)\n",
    "# frames = np.stack(frames)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "original = (int(0.05 * n_width), int(n_height - (0.1 * n_height)))\n",
    "fontScale              = 0.7\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "write_angles = True\n",
    "\n",
    "wait_key = 101\n",
    "i = 0\n",
    "direction = 1\n",
    "\n",
    "manual = False\n",
    "\n",
    "#camera vector based straight road. (Yaw)\n",
    "show_direction_v = False\n",
    "scale_factor = 200\n",
    "angle_factor = 1\n",
    "camera_v = np.array([1, 0]).T * scale_factor\n",
    "# camera_v = rotate_v(camera_v, (math.pi / 2) * angle_factor, False)\n",
    "pos = np.array([int(n_width / 2), int(n_height - (0.3 * n_height))]).T\n",
    "\n",
    "fixed_v = np.array([0, 1]).T * scale_factor\n",
    "fixed_color = (0, 0, 255)\n",
    "\n",
    "v_color = (255, 255, 255)\n",
    "\n",
    "# cv2.namedWindow(\"output\", cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.resizeWindow(\"output\", width, height) \n",
    "\n",
    "# transformation = Crop(int(width * 0.1), int(width - width * 0.1), int(height *0.45), int(height - height * 0.30), True)\n",
    "# transformation = transform\n",
    "# transformation=to_open_cv\n",
    "transformation = None\n",
    "while i < len(frames) and i >= 0:\n",
    "    frame = frames[i].copy()\n",
    "    if transformation is not None:\n",
    "        frame = transformation(frame)\n",
    "    # frame = np.copy(frames[i])\n",
    "    \n",
    "    if write_angles:\n",
    "        cv2.putText(frame, f\"{i} {angles[i]}\", \n",
    "            original, \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            lineType)\n",
    "    \n",
    "    if not math.isnan(angles[i][1]) and show_direction_v:\n",
    "        v = np.copy(camera_v)\n",
    "        v = rotate_v(v, angles[i][1], False)\n",
    "        # v = inv_rotate_v(v, angles[i][1] * angle_factor, False)\n",
    "        draw_arrow(frame, v, pos, v_color)\n",
    "    \n",
    "        # cv2.putText(frame, f\"{v}\", \n",
    "        #     (int(0.05 * n_width), int(n_height - (0.2 * n_height))), \n",
    "        #     font, \n",
    "        #     fontScale,\n",
    "        #     fontColor,\n",
    "        #     lineType)\n",
    "    \n",
    "    cv2.imshow(\"output\", frame)\n",
    "\n",
    "    key = cv2.waitKey(wait_key)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('p'):\n",
    "        while cv2.waitKey(500) != ord('p'):\n",
    "            continue\n",
    "    elif key == ord('e'): #increase speed\n",
    "        if wait_key > 1: \n",
    "            wait_key -= 20\n",
    "    elif key == ord('w'): #decrease speed\n",
    "        if wait_key < 5001:\n",
    "            wait_key += 20\n",
    "    elif key == ord('a'): #forward one frame\n",
    "        i -= 1\n",
    "    elif key == ord('d'): #back one frame\n",
    "        i += 1\n",
    "    elif key == ord('m'): #manual skip\n",
    "        manual = not manual\n",
    "    elif key == ord('f'): #forward\n",
    "        direction = 1\n",
    "    elif key == ord('r'): #reverse \n",
    "        direction = -1\n",
    "\n",
    "    if not manual:\n",
    "        i += direction\n",
    "\n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}